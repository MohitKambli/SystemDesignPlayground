Potential Deep-Dives:
- With the core functional requirements met, it's time to dig into the non-functional requirements via deep dives.
1) How do we improve the booking experience by reserving tickets?
    - The current solution, while it technically works, results in a horrible user experience.
    - No one wants to spend 5 minutes filling out a payment form only to find out the tickets they wanted are no longer available because someone else typed their credit card info faster.
    - If you've ever used similar sites to book event tickets, airline tickets, hotels, etc., you've probably seen a timer counting down the time you have to complete your purchase.
    - This is a common technique to reserve the tickets for a user while they are checking out.
    - We need to ensure that the ticket is locked for the user while they are checking out.
    - We also need to ensure that if the user abandons the checkout process, the ticket is released for other users to purchase.
    - Finally, we need to ensure that if the user completes the checkout process, the ticket is marked as sold and the booking is confirmed.
    - Here are a couple ways we could do this:
        a) Pessimistic Locking
            a.1) Approach
                - A bad solution many candidates propose for this problem is to use long-running database locks (sometimes referred to as "interactive transactions").
                - In this method, the database is directly utilized to lock a specific ticket row, ensuring exclusive access to the first user trying to book it.
                - This is typically done using the SELECT FOR UPDATE statement in PostgreSQL, which locks the selected row(s) as part of a database transaction.
                - The lock on the row is maintained until the transaction is either committed or rolled back.
                - During this time, other transactions attempting to select the same row with SELECT FOR UPDATE will be blocked until the lock is released.
                - This ensures that only one user can process the ticket booking at a time.
                - When it comes to unlocking, there are two cases we need to consider:
                    a.1.1) If the user finalizes the purchase, the transaction is committed, the database lock is released, and the ticket status is set to "Booked".
                    a.1.2) 
                        - If the user takes too long or abandons the purchase, the system has to rely on their subsequent actions or session timeouts to release the lock.
                        - This introduces the risk of tickets being locked indefinitely if not appropriately handled.
            a.2) Challenges
                - Why is this a bad idea? Well, database locks are meant to be used for short periods of time (a single, near-instant, transaction).
                - Keeping a transaction open for a long period (like the 5-minute lock duration) is generally not advisable.
                - It can strain database resources and increase the risk of lock contention and deadlocks.
                - Additionally, SQL DBs like PostgreSQL doesn't natively support lock timeouts within transactions.
                - Implementing a timeout would require application-level management and additional complexity.
                - Finally, this approach may not scale well under high load, as prolonged locks can lead to increased wait times for other users and potential performance bottlenecks.
                - Handling edge cases, such as application crashes or network issues, becomes more challenging, as these could leave locks in an uncertain state.
        b) Status & Expiration Time with Cron
            b.1) Approach
                - A better solution is to lock the ticket by adding a status field and expiration time on the ticket table.
                - The ticket can then be in 1 of 3 states: available, reserved, booked.
                - This allows us to track the status of each ticket and automatically release the lock once the expiration time is reached.
                - When a user selects a ticket, the status changes from "available" to "reserved", and the current timestamp is recorded.
                - Now lets think about how we handle unlocking with this approach:
                    b.1.1) If the user finalizes the purchase, the status changes to "booked", and the lock is released.
                    b.1.2)
                        - If the user takes too long or abandons the purchase, the status changes back to "available" once the expiration time is reached, and the lock is released.
                        - The tricky part here is how we handle the expiration time.
                        - We could use a cron job to periodically query for rows with "reserved" status where the time elapsed exceeds the lock duration and then set them back to "available".
                        - This is much better, but the lag between the elapsed time and the time the row is changed is not ideal for popular events.
                        - Ideally, the lock should be removed almost exactly after expiration.
            b.2) Challenges
                - Whether we use the cron job or on-demand approach, they both have significant drawbacks:
                Cron Job Approach:
                    b.2.1) Delay in Unlocking
                        - There's an inherent delay between the ticket expiration and the cron job execution, leading to inefficiencies, particularly for high-demand events.
                        - Tickets might remain unavailable for purchase even after the expiration time, reducing booking opportunities.
                    b.2.2) Reliability Issues
                        - If the cron job experiences failures or delays, it can cause significant disruptions in the ticket booking process, leading to customer dissatisfaction and potential revenue loss.
        c) Implicit Status with Status and Expiration Time
            c.1) Approach
                - We can do even better than our cron-based solution by recognizing the the status of any given ticket is the combination of two attributes: whether it's available OR whether it's been reserved but the reservation has expired.
                - Rather than using long-running interactive transactions or locks, we can create short transactions to update the fields on the ticket record (e.g. changing "available" to "reserved" and setting expiration to +10 minutes).
                - Inside these transactions we can confirm the ticket is available before reserving it or that the expiration on the previous reservation has passed.
                - So, in pseudocode, our transaction looks like this:
                    c.1.1)
                        - We begin a transaction
                        - We check to see if the current ticket is either AVAILABLE or (RESERVED but expired)
                        - We update the ticket to RESERVED with expiration now + 10 minutes.
                        - We commit the transaction.
                - This guarantees only one user will be able to reserve or book a ticket and that users will be able to claim tickets from expired reservations.
            c.2) Challenges
                - Our read operations are going to be be slightly slower by needing to filter on two values.
                - We can partly solve this by utilizing materialized views or other features of modern RDBMS's together with a compound index.
                - Our database table is also less legible for other consumers of the data, since some reservations are actually expired.
                - We can solve that problem by utilizing a cron or periodic sweep job like above, with the very important difference that our system behavior will not be effected if that sweep is delayed.
        d) Distributed Lock with TTL
            d.1) Approach
                - Another great solution is to implement a distributed lock with a TTL (Time To Live) using a distributed system like Redis.
                - Redis is an in-memory data store that supports distributed locks and is well-suited for high-concurrency environments.
                - It offers high availability and can be used to implement a distributed lock mechanism for the ticket booking process
                - Here is how it would work:
                    d.1.1)
                        - When a user selects a ticket, acquire a lock in Redis using a unique identifier (e.g., ticket ID) with a predefined TTL (Time To Live).
                        - This TTL acts as an automatic expiration time for the lock.
                    d.1.2) 
                        - If the user completes the purchase, the ticket's status in the database is updated to "Booked", and the lock in Redis is manually released by the application after the TTL.
                    d.1.3)
                        - If the TTL expires (indicating the user did not complete the purchase in time), Redis automatically releases the lock.
                        - This ensures that the ticket becomes available for booking by other users without any additional intervention.
                - Now our Ticket table only has two states: available and booked.
                - Locking of reserved tickets is handled entirely by Redis.
                - The key-value pair in Redis is the ticket ID and the value is the user ID.
                - This way we can ensure that when a user confirms the booking, they are the user who reserved the ticket.
            d.2) Challenges
                - The main downside comes with handling failures.
                - If our lock goes down for any reason, then we have a period of time where user experience is degraded.
                - Note that we will still never have a "double booking" since our database will use OCC or any other concurrency control to ensure this.
                - The downside is just that users can get an error after filling out their payment details if someone beats them to it.
                - This sucks, but I would argue that it is a better outcome than having all tickets appear unavailable (as would be the case if the cron job in our previous solution failed).
    - Now, when a user wants to book a ticket:
        1.1) A user will select a seat from the interactive seat map. This will trigger a POST /bookings with the ticketId associated with that seat.
        1.2) The request will be forwarded from our API gateway onto the Booking Service.
        1.3) The Booking Service will lock that ticket by adding it to our Redis Distributed Lock with a TTL of 10 minutes (this is how long we will hold the ticket for).
        1.4) The Booking Service will also write a new booking entry in the DB with a status of in-progress.
        1.5) We will then respond to the user with their newly created bookingId and route the client to a the payment page.
        1.6) If the user stops here, then after 10 minutes the lock is auto-released and the ticket is available for another user to purchase.
        1.7) 
            - The user will fill out their payment details and click “Purchase.”
            - In doing so, the payment (along with the bookingId) gets sent to Stripe for processing and Stripe responds via webhook that the payment was successful.
        1.8) 
            - Upon successful payment confirmation from Stripe, our system's webhook retrieves the bookingId embedded within the Stripe metadata.
            - With this bookingId, the webhook initiates a database transaction to concurrently update the Ticket and Booking tables.
            - Specifically, the status of the ticket linked to the booking is changed to "sold" in the Ticket table.
            - Simultaneously, the corresponding booking entry in the Booking table is marked as "confirmed."
        1.9) Now the ticket is booked!

2) How is the view API going to scale to support 10s of millions of concurrent requests during popular events?
    - In our non-functional requirements we mentioned that our view and search paths need to be highly available, including during peak traffic scenarios.
    - To accomplish this, we need a combination of load balancing, horizontal scaling, and caching.
        2.1) Caching, Load Balancing and Horizontal Scaling
            2.1.a) Approach
                2.1.a.1) Caching
                    - Prioritize caching for data with high read rates and low update frequency, such as event details (names, dates, venue information), performer bios, and static venue details like location and capacity.
                    - Because this data does not change frequently, we can cache it like crazy to heavily minimize the load of our SQL DB and meet our high availability requirements.
                    - Cache key-value pairs like eventId:eventObject to efficiently serve frequently accessed data.
                    - Utilize Redis or Memcached as in-memory data stores, leveraging their speed for handling large volumes of read operations.
                    - A read-through cache strategy ensures data availability, with cache misses triggering a database read and subsequent cache update.
                    - Set up database triggers to notify the caching system of data changes, such as updates in event dates or performer lineups, to invalidate relevant cache entries.
                    - Implement a Time-to-Live policy for cache entries, ensuring periodic refreshes.
                    - These TTLs can be long for static data like venue information and short for frequently updated data like event availability.
                2.1.a.2) Load Balancing
                    - Use algorithms like Round Robin or Least Connections for even traffic distribution across server instances.
                    - Implement load balancing for all horizontally scaled services and databases.
                2.1.a.3) Horizontal Scaling
                    - The Event Service is stateless which allows us to horizontally scale it to meet demand.
                    - We can do this by adding more instances of the service and load balancing between them.
            2.1.b) Challenges
                - One of the primary challenges is maintaining consistency between the cache and the database.
                - This is particularly challenging with frequent updates to event details (but we don't expect this)
                - Managing a large number of instances presents complexities.
                - Ensuring smooth deployment and effective rollback procedures adds to the operational challenges.

3) How will the system ensure a good user experience during high-demand events with millions simultaneously booking tickets?
    - With popular events, the loaded seat map will go stale quickly.
    - Users will grow frustrated as they repeatedly click on a seat, only to find out it has already been booked.
    - We need to ensure that the seat map is always up to date and that users are notified of changes in real-time.
        3.a) SSE for Real-Time Seat Updates
            3.a.1) Approach
                - To ensure that the seat map is always up to date, we can use Server-Sent Events (SSE) to push updates to the client in real-time.
                - This will allow us to update the seat map as soon as a seat is booked (or reserved) by another user without needing to refresh the page.
                - SSE is a unidirectional communication channel between the server and the client.
                - It allows the server to push data to the client without the client having to request it.
            3.a.2) Challenges
                - While this approach works well for moderately popular events, the user experience will still suffer during extremely popular events.
                - In the "Taylor Swift case," for example, the seat map will immediately fill up, and users will be left with a disorienting and overwhelming experience as available seats disappear in an instant.
        3.b) Virtual Waiting Queue for Extremely Popular Events
            3.b.1) Approach
                - For extremely popular events, we can implement an admin enabled virtual waiting queue system to manage user access during times of exceptionally high demand.
                - Users are placed in this queue before even being able to see the booking page (seat map selected)
                - It is designed to control the flow of users accessing the booking interface, thereby preventing system overload and enhancing the user experience.
                - Here is how it would work at a high level:
                    3.b.1.1)
                    - When a user requests to view the booking page, they are placed in a virtual queue.
                    - We establish a WebSocket connection with their client and add the user to the queue using their unique WebSocket connection.
                    - Periodically or based on certain criteria (like tickets booked), dequeue users from the front of the queue.
                    - Notify these users via their WebSocket connection that they can proceed to purchase tickets.
                    - At the same time, update the database to reflect that this user is now allowed to access the ticket purchasing system.
            3.b.2) Challenges
                - Long wait times in the queue might lead to user frustration, especially if the estimated wait times are not accurate or if the queue moves slower than expected.
                - By pushing updates to the client in real-time, we can mitigate this risk by providing users with constant feedback on their queue position and estimated wait time.
            
4) How can you improve search to ensure we meet our low latency requirements?
    - Our current search implementation is not going to cut it.
    - Queries to search for events based on keywords in the name, description, or other fields will require a full table scan because of the wildcard in the LIKE clause.
    - This can be very slow, especially as the number of events grows.
        -- Slow Query
            SELECT * 
            FROM Events
            WHERE name LIKE '%Taylor%' 
            OR description LIKE '%Taylor%'
    - Let's look at some strategies to improve search performance and ensure we meet our low latency requirements.
    4.1) Indexing & SQL Query Optimization
        4.1.a) Approach
            - Create indexes on the Event, Performer, and Venues tables to improve query performance.
            - Indexes allow for faster data retrieval by mapping the values in specific columns to their corresponding rows in the table.
            - This speeds up search queries by reducing the number of rows that need to be scanned.
            - We want to index the columns that are frequently used in search queries, such as event name, event date, performer name, and venue location.
            - Optimize queries to improve performance.
            - his includes techniques like using EXPLAIN to analyze query execution plans, avoiding SELECT * queries, and using LIMIT to restrict the number of rows returned.
            - Additionally, using UNION instead of OR for combining multiple queries can improve performance.
        4.1.b) Challenges
            - Standard indexes are less effective for queries involving partial string matches (e.g., searching for "Taylor" instead of the full "Taylor Swift").
            - This requires additional considerations, like implementing full-text search capabilities or using LIKE operators, which can be less efficient.
            - While indexes improve query performance, they can also increase storage requirements and slow down write operations, as each insert or update may necessitate an index update.
            - Finding the right balance between the number of indexes and overall database performance, especially considering the diverse and complex query patterns in a ticketing system.
    4.2) Full-text Indexes in the DB
        4.2.a) Approach
            - We can extend the basic indexing strategy above to utilize full-text indexes in our database, if available.
            - For popular SQL databases like MySQL or Postgres, full text extensions are available which utilize search engines like Lucene under the covers.
            - These make queries for specific strings like "Taylor" or "Swift" much faster than doing a full table scan using LIKE.
        4.2.b) Challenges
            - Full text indexes require additional storage space and can be slower to query than standard indexes.
            - Full text indexes can be more difficult to maintain, as they require special handling in both queries and in maintaining the database.
    4.3) Use a Full-text Search Engine like Elasticsearch
        4.3.a) Approach
            - Add Elasticsearch or a similar full-text search engine.
            - Elasticsearch is a powerful search engine that excels in full-text search, complex query execution, and handling high-volume traffic efficiently.
            - At its core, Elasticsearch operates using inverted indexes, a key feature that makes it highly efficient for search operations.
            - Inverted indexes allow Elasticsearch to quickly locate and retrieve data by mapping each unique word to the documents or records it appears in, significantly speeding up search queries.
            - To make sure the data in Elasticsearch is always in sync with the data in our SQL DB, we can use change data capture (CDC) for real-time or near-real-time data synchronization from PostgreSQL to Elasticsearch.
            - This setup captures changes in the PostgreSQL database, such as inserts, updates, and deletes, and replicates them to the Elasticsearch index.
            - We can enable fuzzy search functionality with Elasticsearch, which allows for error tolerance in search queries.
            - This is way we can handle typos and slight variations in spellings such as "Taylor Swift" vs "Tayler Swift".
            - This is something that would be very difficult to do with SQL alone.
        4.3.b) Challenges
            - Keeping the Elasticsearch index synchronized with PostgreSQL can be complex and requires a reliable mechanism to ensure data consistency.
            - Maintaining an Elasticsearch cluster adds additional infrastructure complexity and cost.

5) How can you speed up frequently repeated search queries and reduce load on our search infrastructure?
    5.1) Implement Caching Strategies Using Redis or Memcached
        5.1.a) Approach
            - Use caching mechanisms like Redis or Memcached to store the results of frequently executed search queries.
            - This reduces the load on the search infrastructure by serving repeated queries from the cache instead of hitting the database or search engine repeatedly.
            - Key Design: Construct cache keys based on search query parameters to uniquely identify each query.
            - Time-To-Live (TTL): Set appropriate TTLs for cached data to ensure freshness and relevance of the information.
            - For example, a cache entry may look like:
                {
                    "key": "search:keyword=Taylor Swift&start=2021-01-01&end=2021-12-31",
                    "value": [event1, event2, event3],
                    "ttl": 60 * 60 * 24 // 24 hours
                }
        5.1.b) Challenges
            - Efficiently managing cache invalidation can be challenging.
            - Stale or outdated data in the cache can lead to incorrect search results being served to users.
            - This becomes increasingly complex if you cache fuzzy search results.
            - You can use a combination of TTLs and cache invalidation triggers built around cache tags to ensure data consistency.
            - Frequent cache misses can lead to increased load on the search infrastructure, especially during peak times.
    5.2) Implement Query Result Caching and Edge Caching Techniques
        5.2.a) Approach
            - Conveniently, Elasticsearch has built-in caching capabilities that can be leveraged to store results of frequent queries.
            - This reduces the query processing load on the search engine itself.
            - The node query cache in Elasticsearch is an LRU cache shared by all shards on a node, caching results of queries used in the filter.
            - Additionally, Elasticsearch's shard-level request cache is used for caching search responses consisting of aggregation.
            - This can be used for adaptive caching strategies, where the system learns and caches results of the most frequently executed queries over time.
            - We can also utilize CDNs to cache search results geographically closer to the user, reducing latency and improving response times.
            - For example, this could mean integrating AWS CloudFront.
            - Note, this only makes sense if search results are not personalized, meaning that the same search query will return the same results for all users.
        5.2.b) Challenges
            - Ensuring consistency between cached data and real-time data requires sophisticated synchronization mechanisms.
            - You need to ensure you invalidate the cache whenever the underlying data changes (like when a new event is announced).
            - Since search queries and the potential results aren't connected, this is a challenge.
            - This approach demands more infrastructure support, including integration with CDNs and managing adaptive caching systems.
